{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXgiL3hWzuZvVBhn8xqGaF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1.Document"],"metadata":{"id":"dH1UP23NDEgu"}},{"cell_type":"code","source":["# pip install llama_index"],"metadata":{"id":"yiXpammh9309"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import SummaryIndex, Document\n","\n","document = Document.example()"],"metadata":{"id":"kLhhXs6I-pte","executionInfo":{"status":"ok","timestamp":1711545945018,"user_tz":-480,"elapsed":450,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["#### 只有一个数据时是元组tuple\n","document = Document(\n","    text=\"text\",\n","    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\n",")"],"metadata":{"id":"rSIE5oWwEnqE","executionInfo":{"status":"ok","timestamp":1711546200048,"user_tz":-480,"elapsed":369,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["## 手动指定document的metadata，只保留指定项\n","document.metadata = {\"filename\": \"super_secret_document.txt\"}"],"metadata":{"id":"q5EpotpgF92q","executionInfo":{"status":"ok","timestamp":1711546210412,"user_tz":-480,"elapsed":388,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["document"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTdDWH2wGEfv","executionInfo":{"status":"ok","timestamp":1711546212363,"user_tz":-480,"elapsed":410,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"2f35463f-9d41-4752-b41d-6ce7ff268fed"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(id_='3a62c1f1-b0e9-4687-bd63-5132de26c4e3', embedding=None, metadata={'filename': 'super_secret_document.txt'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='text', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["from llama_index.core import Document\n","from llama_index.core.schema import MetadataMode\n","\n","document = Document(\n","    text=\"This is a super-customized document\",\n","    metadata={\n","        \"file_name\": \"super_secret_document.txt\",\n","        \"category\": \"finance\",\n","        \"author\": \"LlamaIndex\",\n","    },\n","    ##可以设置llm和embed的排除项（一般使用默认）\n","    excluded_llm_metadata_keys=[\"file_name\"],\n","    metadata_seperator=\"::\",\n","    metadata_template=\"{key}=>{value}\",\n","    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",")"],"metadata":{"id":"jlmkUsKeG0Bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import Document\n","### 有很多数据时print是list\n","text_list = ['This is a super-customized document',\n","        'How do we best augment LLMs with our own private data?',\n","        'Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.']\n","documents = [Document(text=t) for t in text_list]\n","documents"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44yMg3ELHZZj","executionInfo":{"status":"ok","timestamp":1711546577600,"user_tz":-480,"elapsed":4,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"f9c4941f-0b08-4392-bf7b-147c8f6b7922"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(id_='8e83a854-4bb1-442c-8dae-e83fae4979c6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This is a super-customized document', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," Document(id_='c860e04b-8c77-49a3-a7d1-af9f92561cfd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='How do we best augment LLMs with our own private data?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," Document(id_='a8a3c9ad-dbf5-4e72-b768-4940a712ce11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["from llama_index.core import Document\n","### 有很多数据时print是list\n","text_list = ['Happy new year!',\n","        'Hello world!']\n","meta_list = [{\"filename\": \"ccc\", \"category\": \"one\"},\n","        {\"filename\": \"bbb\", \"category\": \"two\"},]\n","documents = [Document(text=t) for t in text_list]\n","documents = [Document(metadata=k) for k in meta_list]\n","documents ##这样写的数据只保留一次"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cVH9dw5XIG3m","executionInfo":{"status":"ok","timestamp":1711547076285,"user_tz":-480,"elapsed":4,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"699b4a31-f085-40f9-a6d0-a017551bd778"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(id_='bdf5c10d-c9c8-4f7f-832d-a6c105f9f565', embedding=None, metadata={'filename': 'ccc', 'category': 'one'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," Document(id_='e6dcbc29-3390-4c07-95e1-7f0dfda44612', embedding=None, metadata={'filename': 'bbb', 'category': 'two'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["doc_list = [['Happy new year!',\n","        {\"filename\": \"ccc\",\n","        \"category\": \"one\"}], ##text1+metadata\n","        ['Hello world!',\n","        {\"filename\": \"bbb\",\n","        \"category\": \"two\"}]] ##text2+metadata\n","doc_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YV6vzWZ2JjFH","executionInfo":{"status":"ok","timestamp":1711547046368,"user_tz":-480,"elapsed":3,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"1c7b7838-aeb4-418b-93aa-38f1f2bc9e20"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['Happy new year!', {'filename': 'ccc', 'category': 'one'}],\n"," ['Hello world!', {'filename': 'bbb', 'category': 'two'}]]"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["documents = [Document(text=t,metadata=k) for t,k in doc_list]\n","documents  ##这样写的数据保留多个key"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YQYHsnfJZi-","executionInfo":{"status":"ok","timestamp":1711547098126,"user_tz":-480,"elapsed":2,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"3a6f401a-0410-40e2-9ebe-64e799999eb0"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(id_='b25be4a3-fde9-4346-8bd9-bf5abc059281', embedding=None, metadata={'filename': 'ccc', 'category': 'one'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Happy new year!', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," Document(id_='ee0464a7-a3fe-403c-a589-89c602cd2775', embedding=None, metadata={'filename': 'bbb', 'category': 'two'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Hello world!', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["document1 = Document(\n","    text=\"This is a super-customized document\",\n","    metadata={\n","        \"file_name\": \"super_secret_document.txt\",\n","        \"category\": \"finance\",\n","        \"author\": \"LlamaIndex\"})\n","document2 = Document(\n","    text=\"Hello world!\",\n","    metadata={\n","        \"file_name\": \"computersss.txt\",\n","        \"category\": \"RAG\",\n","        \"author\": \"Human\"})\n","##或者这样写，把多个document用[.. , ..]连接\n","document = [document1, document2]\n","document"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eW5Dc34IL1mX","executionInfo":{"status":"ok","timestamp":1711550175496,"user_tz":-480,"elapsed":329,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"1455b8ef-1a78-4adf-8944-042d88e375cc"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(id_='e0572a2a-06c8-4fba-b4f4-5e42be96266b', embedding=None, metadata={'file_name': 'super_secret_document.txt', 'category': 'finance', 'author': 'LlamaIndex'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This is a super-customized document', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," Document(id_='adaa4c8c-d2d9-4f84-8a79-c9df6cdd0593', embedding=None, metadata={'file_name': 'computersss.txt', 'category': 'RAG', 'author': 'Human'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Hello world!', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","source":["# 2.Nodes"],"metadata":{"id":"daps5IjpDJKW"}},{"cell_type":"code","source":["SentenceSplitter??\n","# Node parsers are a simple abstraction that take a\n","# list of documents, and chunk them into Node objects,\n","# such that each node is a specific chunk of the parent document.\n","\n","# When a document is broken into nodes, all of it's\n","# attributes are inherited to the children nodes\n","# (i.e. metadata, text and metadata templates, etc.)"],"metadata":{"id":"jssvDilROJlz","executionInfo":{"status":"ok","timestamp":1711548186500,"user_tz":-480,"elapsed":3,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["from llama_index.core.node_parser import SentenceSplitter\n","## sentencesplitter定义每个document被划分的chunk大小\n","## 以及重叠的数量\n","parser = SentenceSplitter()\n","## get_nodes_from...只在list作用\n","nodes = parser.get_nodes_from_documents(documents)"],"metadata":{"id":"nS4NuPmKDC0E","executionInfo":{"status":"ok","timestamp":1711547285712,"user_tz":-480,"elapsed":4,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["nodes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGIfuWDYKw5V","executionInfo":{"status":"ok","timestamp":1711547293524,"user_tz":-480,"elapsed":334,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"c3a7333a-15eb-46a1-d647-883437de6c59"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TextNode(id_='95e91f8d-0b9a-4d90-9543-96b8ed0b5d7c', embedding=None, metadata={'filename': 'ccc', 'category': 'one'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b25be4a3-fde9-4346-8bd9-bf5abc059281', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'ccc', 'category': 'one'}, hash='9fa12b7a0f647edce1d710d0051320c96b6f559391ee6909d40a5d7281df631b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='57e75634-3ee5-45ba-8adc-19e1c885a84a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c7e06b2c49ed32dda4b3999345c16c9735306ea61a749e39f1c16c5a05a7af37')}, text='Happy new year!', start_char_idx=0, end_char_idx=15, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='57e75634-3ee5-45ba-8adc-19e1c885a84a', embedding=None, metadata={'filename': 'bbb', 'category': 'two'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ee0464a7-a3fe-403c-a589-89c602cd2775', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'bbb', 'category': 'two'}, hash='119025c41a6a78dd60d92dc0939347f67db22caf095ea521e97aee8d634639eb'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='95e91f8d-0b9a-4d90-9543-96b8ed0b5d7c', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'ccc', 'category': 'one'}, hash='9fa12b7a0f647edce1d710d0051320c96b6f559391ee6909d40a5d7281df631b')}, text='Hello world!', start_char_idx=0, end_char_idx=12, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n","## 可以自己创建node\n","node1 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n","node2 = TextNode(text=\"<text_chunk>\", id_=\"<node_id>\")\n","# set relationships\n","node1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n","    node_id=node2.node_id\n",")\n","node2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n","    node_id=node1.node_id\n",")\n","nodes = [node1, node2]"],"metadata":{"id":"Ub8YnQk6LmH6","executionInfo":{"status":"ok","timestamp":1711547529762,"user_tz":-480,"elapsed":3,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["nodes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzAk9ot8LsZT","executionInfo":{"status":"ok","timestamp":1711547537276,"user_tz":-480,"elapsed":3,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"f64350ba-5e2f-43e0-f8ae-fb2bc3ba64c6"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TextNode(id_='<node_id>', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='<node_id>', node_type=None, metadata={}, hash=None)}, text='<text_chunk>', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='<node_id>', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='<node_id>', node_type=None, metadata={}, hash=None)}, text='<text_chunk>', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["text='\\nContext\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.\\n'"],"metadata":{"id":"KpLIW9viSdD8","executionInfo":{"status":"ok","timestamp":1711549388722,"user_tz":-480,"elapsed":2,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["##在一个document中，使用split进行拆分变成node1\n","##每个node会继承document父级中的属性（比如：metadata）\n","node_parser = SentenceSplitter(chunk_size=200, chunk_overlap=20)\n","\n","nodes = node_parser.get_nodes_from_documents(\n","    [Document(text=text,\n","          metadata={\n","              \"filename\":\"bbb\",\n","              \"categery\":\"kkk\"\n","          })], show_progress=False\n",")\n","nodes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtGvl90MSAQw","executionInfo":{"status":"ok","timestamp":1711549536720,"user_tz":-480,"elapsed":392,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"8b82248e-c6a2-4e91-b8aa-14b17d9a021e"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TextNode(id_='d5a472d4-ff89-4b31-b8b5-8147e6e8bf7f', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d3ce0164-3fbe-491d-9464-76908bb58ca1', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='edf487fd1b23742386da2062ee4659ce003e58bf03d2f92904df91fc9173234c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='303b2720-5747-4db6-9c91-4570033d18b1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6634fe1a5cec75f4cd8570269432fd443b5258b4c2128b0f53f5e696a5d4cb7e')}, text='Context\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.', start_char_idx=1, end_char_idx=803, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='303b2720-5747-4db6-9c91-4570033d18b1', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d3ce0164-3fbe-491d-9464-76908bb58ca1', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='edf487fd1b23742386da2062ee4659ce003e58bf03d2f92904df91fc9173234c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='d5a472d4-ff89-4b31-b8b5-8147e6e8bf7f', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='ade79b147926e67d07cc3a6ee30b11dcc9a4fdd6f71edb3382a04fc7600c061c')}, text='Allows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.', start_char_idx=804, end_char_idx=1279, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["from llama_index.core.node_parser import TokenTextSplitter\n","##基于token的node划分\n","splitter = TokenTextSplitter(\n","    chunk_size=1024,\n","    chunk_overlap=20,\n","    separator=\" \",\n",")\n","nodes = splitter.get_nodes_from_documents(\n","    [Document(text=text,\n","          metadata={\n","              \"filename\":\"bbb\",\n","              \"categery\":\"kkk\"\n","          })], show_progress=False\n",")\n","nodes\n","nodes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFmiywq9WzXR","executionInfo":{"status":"ok","timestamp":1711550487724,"user_tz":-480,"elapsed":320,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"f55df020-9307-4cfe-e89c-13e89511be20"},"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TextNode(id_='e65a83a0-61f8-4e71-af49-91f9b8c2333a', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ad162687-3282-46be-85e9-9d527993071f', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='edf487fd1b23742386da2062ee4659ce003e58bf03d2f92904df91fc9173234c')}, text='Context\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.', start_char_idx=1, end_char_idx=1279, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["from llama_index.core.node_parser import HierarchicalNodeParser\n","# 结构化node划分，2048-->512-->128\n","node_parser = HierarchicalNodeParser.from_defaults(\n","    chunk_sizes=[2048, 512, 128]\n",")\n","nodes = node_parser.get_nodes_from_documents(\n","    [Document(text=text,\n","          metadata={\n","              \"filename\":\"bbb\",\n","              \"categery\":\"kkk\"\n","          })], show_progress=False\n",")\n","nodes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iL_nigTIWPNC","executionInfo":{"status":"ok","timestamp":1711550320860,"user_tz":-480,"elapsed":4,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"ad977085-c832-40a9-f6d1-f0dd9afd614b"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TextNode(id_='a5dba4de-0ffa-425d-9636-643bbc235379', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a1e52827-a14f-406b-8085-d21cce80d183', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='edf487fd1b23742386da2062ee4659ce003e58bf03d2f92904df91fc9173234c'), <NodeRelationship.CHILD: '5'>: [RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779')]}, text='Context\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.', start_char_idx=1, end_char_idx=1279, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='5704f53c-d732-459a-a293-1ec4c0016b3b', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a5dba4de-0ffa-425d-9636-643bbc235379', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779'), <NodeRelationship.PARENT: '4'>: RelatedNodeInfo(node_id='a5dba4de-0ffa-425d-9636-643bbc235379', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779'), <NodeRelationship.CHILD: '5'>: [RelatedNodeInfo(node_id='ef92ab5e-a123-408a-b304-1ee88936fe33', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='cf3c165a76fec5f0ccfb69ea37200cbcea7f17e78cf64199964cd12fda77cb88'), RelatedNodeInfo(node_id='3a939445-7f32-4790-ab2a-19acf3a11b7d', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='bc3990ea5cd3be945ae4e7a2c83075f798a751fd18076132b76bd34ef62c214f'), RelatedNodeInfo(node_id='eacbbae7-85d8-4553-8990-a6d4a04ef0a3', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='c10f7148be7e0d1cf2c31722ba52b1193c1a1536db007178a0877feeb59a4241')]}, text='Context\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.', start_char_idx=0, end_char_idx=1278, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='ef92ab5e-a123-408a-b304-1ee88936fe33', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3a939445-7f32-4790-ab2a-19acf3a11b7d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2236e9bc5c07b51e9e9cc0c351a71ae3a996e2f263418d25f6325d3ca7e0b3d9'), <NodeRelationship.PARENT: '4'>: RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779')}, text='Context\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps.', start_char_idx=0, end_char_idx=406, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='3a939445-7f32-4790-ab2a-19acf3a11b7d', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ef92ab5e-a123-408a-b304-1ee88936fe33', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='cf3c165a76fec5f0ccfb69ea37200cbcea7f17e78cf64199964cd12fda77cb88'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eacbbae7-85d8-4553-8990-a6d4a04ef0a3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6634fe1a5cec75f4cd8570269432fd443b5258b4c2128b0f53f5e696a5d4cb7e'), <NodeRelationship.PARENT: '4'>: RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779')}, text='LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.', start_char_idx=345, end_char_idx=802, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n"," TextNode(id_='eacbbae7-85d8-4553-8990-a6d4a04ef0a3', embedding=None, metadata={'filename': 'bbb', 'categery': 'kkk'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3a939445-7f32-4790-ab2a-19acf3a11b7d', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='bc3990ea5cd3be945ae4e7a2c83075f798a751fd18076132b76bd34ef62c214f'), <NodeRelationship.PARENT: '4'>: RelatedNodeInfo(node_id='5704f53c-d732-459a-a293-1ec4c0016b3b', node_type=<ObjectType.TEXT: '1'>, metadata={'filename': 'bbb', 'categery': 'kkk'}, hash='9cd50be62456fa7ddb00c9b6673d630075584259df63c7caab03c92c11a36779')}, text='Allows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.', start_char_idx=803, end_char_idx=1278, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["##其他类型的node parser模块\n","##https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules/"],"metadata":{"id":"EvsarHFxVFOY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.load data"],"metadata":{"id":"K9yebBu2TqTR"}},{"cell_type":"code","source":["##官网提供了很多的load模块\n","##https://docs.llamaindex.ai/en/stable/module_guides/loading/connector/modules/"],"metadata":{"id":"bCLUVgN6X66z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import SimpleDirectoryReader\n","\n","reader = SimpleDirectoryReader(input_dir=\"/content/test\")\n","documents = reader.load_data()\n","documents ##load图像的时候，默认会把file_name等key值排除"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"daok2RkzTqAI","executionInfo":{"status":"ok","timestamp":1711549636978,"user_tz":-480,"elapsed":385,"user":{"displayName":"Haoran MA","userId":"13057477922362050042"}},"outputId":"068ff5ff-ebfc-4de6-ec9f-20bb69e47e94"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[ImageDocument(id_='fd289bb6-112d-43ad-92c7-ea5c74933031', embedding=None, metadata={'file_path': '/content/test/1.jpg', 'file_name': '1.jpg', 'file_type': 'image/jpeg', 'file_size': 66221, 'creation_date': '2024-03-27', 'last_modified_date': '2024-03-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path='/content/test/1.jpg', image_url=None, image_mimetype=None, text_embedding=None),\n"," ImageDocument(id_='a9ca06fb-9ee9-4521-8a46-e5ddaa51a94b', embedding=None, metadata={'file_path': '/content/test/2.jpg', 'file_name': '2.jpg', 'file_type': 'image/jpeg', 'file_size': 76371, 'creation_date': '2024-03-27', 'last_modified_date': '2024-03-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path='/content/test/2.jpg', image_url=None, image_mimetype=None, text_embedding=None)]"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":[],"metadata":{"id":"j9HtkC_yX5Rm"},"execution_count":null,"outputs":[]}]}